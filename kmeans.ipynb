{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLG: Unsupervised learning (Part 1)\n",
    "\n",
    "Throughout the laboratories, questions that you should try to answer are highlighted as follows :\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Try to answer these questions / run the proposed experiments for your own comprehension. </p>\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this laboratory, we will work with a different type of problem called unsupervised learning.\n",
    "When we talk about unsupervised learning, it means that we are trying to find **hidden structure** in unlabeled data. Therefore, no simple measure exists to evaluate a potential solution.\n",
    "\n",
    "\n",
    "We will focus on a commonly used algorithm to solve this kind of problem called \"Self Organizing Maps\".\n",
    "As you saw in the theoretical part of the course, the main advantage of this algorithm is its topological ordering, which means that the maps can be visualized as **elastic grids**. Therefore they can be easily plotted.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "For the following exercises, you could need several new packages. Install them as follows:\n",
    "\n",
    "    !pip install name_of_the_missing_module\n",
    "    \n",
    "After these, you should be able to import them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 : Animals database clustering with the K-Means algorithm\n",
    "\n",
    "### Dataset information\n",
    "\n",
    "Each row is an animal, and it is constructed by the presence (1) or absence (0) of 13 different attributes. You can look at the plot hereafter, or generate it yourself with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bd260f4f7f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.array([[1,0,0,1,0,0,0,0,1,0,0,1,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,0,0,0,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,0,0,0,1],\n",
    "                   [1,0,0,1,0,0,0,1,1,0,0,1,1],\n",
    "                   [1,0,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [1,0,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [0,1,0,1,0,0,0,0,1,1,0,1,0],\n",
    "                   [0,1,0,0,1,1,0,0,0,1,0,0,0],\n",
    "                   [0,1,0,0,1,1,0,0,0,0,1,0,0],\n",
    "                   [0,1,0,0,1,1,0,1,0,1,1,0,0],\n",
    "                   [1,0,0,0,1,1,0,0,0,1,0,0,0],\n",
    "                   [0,0,1,0,1,1,0,0,0,1,1,0,0],\n",
    "                   [0,0,1,0,1,1,0,1,0,1,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,1,0,0,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,1,0,0,1,0,0],\n",
    "                   [0,0,1,0,1,1,1,0,0,0,0,0,0]])\n",
    "\n",
    "animals = pd.DataFrame(matrix.astype(float),columns=['small', 'medium', 'big', '2legs', '4legs', 'hair', 'hooves',\n",
    "                                'mane', 'feathers', 'hunt', 'run', 'fly', 'swim'])\n",
    "\n",
    "animals.index = ['dove', 'hen', 'duck', 'goose', 'owl', 'hawk', 'eagle', 'fox',\n",
    "                 'dog', 'wolf', 'cat', 'tiger', 'lion', 'horse', 'zebra', 'cow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8,10))\n",
    "pl.xticks(np.arange(matrix.shape[1]), animals.columns, rotation=90)\n",
    "pl.yticks(np.arange(matrix.shape[0]), animals.index)\n",
    "pl.title('Animals')\n",
    "_ = pl.imshow(matrix, interpolation='nearest', cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are features on which we will run our K-Means algorithm in order to find an inherent data structure, or similarities between samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "kmeans = KMeans(n_clusters=K, n_init=1, init='random').fit(animals.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animals.index)\n",
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in range(K):\n",
    "    print(f'Group {g}')\n",
    "    print('    ', end='')\n",
    "    for a in animals.index[kmeans.labels_ == g]:\n",
    "        print(a, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Observe the animals that are grouped together by K-Means and try different numbers of clusters: K=2,3,4, etc. </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: n_init is a parameter that automatically asks K-means to try different cluster initializations and selects the best result. init='random' asks K-means to randomly initialize the cluster centroids. Please, try init=’k-means++’ and modify n_init to 10 for example and observe the results. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Wine database clustering with K-Means\n",
    "\n",
    "Now, use the K-means algorithm to separate the three types of wine in the Wine dataset (K = 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "\n",
    "features = data.data\n",
    "classes = data.target\n",
    "\n",
    "classes_names = data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, n_init=10, init='k-means++').fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Observe the observations that are grouped together by K-Means. </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Count the number of \"bottles\" that are correctly grouped. What is the accuracy of this unsupervised classification? </p>\n",
    "\n",
    "<p style=\"background-color:#006600; color:#fff;padding:5px; font-weight:bold\">Q: Try to improve the performance of the classification. Does normalizing the data increases the accuracy? Does selecting a reduced number of features improves the accuracy? Why?. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
